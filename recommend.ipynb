{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a386e797-9f79-462f-8d27-5ab8289fd76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/aubustou/git/recommend')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "Path(\".\").absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d0f9b32-aec6-4ca7-85bd-d4efd45b3f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 13:11:27.984522: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-12 13:11:28.438871: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-12 13:11:28.438910: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-12 13:11:28.438914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0be9e609-e628-4f37-ac32-b694e19adae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class personalisedSearcher:\n",
    "    def __init__(self):\n",
    "        self.movies = pd.read_csv(\"ml-25m/movies.csv\")\n",
    "        print(\"Movies loaded\")\n",
    "        self.ratings = pd.read_csv(\"ml-25m/ratings.csv\")\n",
    "        print(\"Ratings loaded\")\n",
    "        self.embeddings = pd.read_csv(\"embeddings/data.csv\", index_col=0)\n",
    "        print(\"Embeddings loaded\")\n",
    "        self.item_tensor = tf.convert_to_tensor(self.embeddings, dtype=tf.float32)\n",
    "        print(\"Item tensor generated\")\n",
    "        self.scann = tfrs.layers.factorized_top_k.ScaNN(num_leaves=1000, \n",
    "                                                        num_leaves_to_search = 100, \n",
    "                                                        k = round(np.sqrt(len(self.item_tensor))))\n",
    "        self.scann.index(self.item_tensor)\n",
    "        print(\"Scann initialized\")\n",
    "        self.model = AutoModel.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "        print(\"Model loaded\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "        print(\"Tokenizer loaded\")\n",
    "        self.recommender = keras.models.load_model('CF')\n",
    "        print(\"CF loaded\")\n",
    "        \n",
    "    def get_user_encodings(self):\n",
    "        user_ids = self.ratings[\"userId\"].unique().tolist()\n",
    "        user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "        userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "        \n",
    "        return user2user_encoded, userencoded2user\n",
    "\n",
    "    def get_movie_encodings(self):\n",
    "        movie_ids = self.ratings[\"movieId\"].unique().tolist()\n",
    "        movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
    "        movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
    "        \n",
    "        return movie2movie_encoded, movie_encoded2movie\n",
    "    \n",
    "    def update_ratings(self):\n",
    "        user2user_encoded, _ = self.get_user_encodings()\n",
    "        movie2movie_encoded, _ = self.get_movie_encodings()\n",
    "        self.ratings[\"user\"] = self.ratings[\"userId\"].map(user2user_encoded)\n",
    "        self.ratings[\"movie\"] = self.ratings[\"movieId\"].map(movie2movie_encoded)\n",
    "        \n",
    "        return self.ratings\n",
    "        \n",
    "    def get_user_history(self, user_id):\n",
    "        df = self.update_ratings()\n",
    "        watched_movies = df[df.userId == user_id]\n",
    "        \n",
    "    def get_candidate_movies(self, query):\n",
    "        encoded_input = self.tokenizer(query, \n",
    "                                  padding=True, \n",
    "                                  truncation=True, \n",
    "                                  max_length=64, \n",
    "                                  return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            model_output = self.model(**encoded_input)\n",
    "        query_embeddings = model_output.pooler_output\n",
    "        query_embeddings = torch.nn.functional.normalize(query_embeddings)\n",
    "        test_case = self.scann(np.array(query_embeddings))\n",
    "        return self.movies.iloc[test_case[1].numpy()[0]][0:11]\n",
    "    \n",
    "    def filter_candidates(self, user_id, query):\n",
    "        movies_watched_by_user = self.ratings[self.ratings.userId == user_id]\n",
    "        candidates = self.get_candidate_movies(query)\n",
    "        movies_not_watched = candidates[\n",
    "            ~candidates[\"movieId\"].isin(movies_watched_by_user.movieId.values)\n",
    "        ][\"movieId\"]\n",
    "        movie2movie_encoded, _ = self.get_movie_encodings()\n",
    "        movies_not_watched = list(set(movies_not_watched).\n",
    "                                  intersection(set(movie2movie_encoded.keys())))\n",
    "        movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
    "        user2user_encoded, _ = self.get_user_encodings()\n",
    "        user_encoder = user2user_encoded.get(user_id)\n",
    "        movie_array = np.hstack(([[user_encoder]] * len(movies_not_watched), movies_not_watched))\n",
    "        \n",
    "        return movie_array, movies_not_watched, movies_watched_by_user\n",
    "    \n",
    "    def personalised_search(self, user_id, query):\n",
    "        movie_array, movies_not_watched, movies_watched_by_user = self.filter_candidates(user_id, query)\n",
    "        scored_items = self.recommender.predict(movie_array).flatten()\n",
    "        top_rated = scored_items.argsort()[-10:][::-1]\n",
    "        _, movie_encoded2movie = self.get_movie_encodings()\n",
    "        recommended_movie_ids = [movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_rated]\n",
    "        \n",
    "        return recommended_movie_ids, movies_watched_by_user\n",
    "    \n",
    "    def print_recs(self, user_id, query):\n",
    "        recommendations, movies_watched_by_user = self.personalised_search(user_id, query)\n",
    "        \n",
    "        print(\"Showing recommendations for user: {}\".format(user_id))\n",
    "        print(\"====\" * 9)\n",
    "        print(\"Movies with high ratings from user\")\n",
    "        print(\"----\" * 8)\n",
    "        top_movies_user = (\n",
    "            movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
    "            .head(5)\n",
    "            .movieId.values\n",
    "        )\n",
    "        movie_df_rows = self.movies[self.movies[\"movieId\"].isin(top_movies_user)]\n",
    "        for row in movie_df_rows.itertuples():\n",
    "            print(row.title, \":\", row.genres)\n",
    "        print(\"----\" * 8)\n",
    "        print(\"Top movie recommendations\")\n",
    "        print(\"----\" * 8)\n",
    "        recommended_movies = self.movies[self.movies[\"movieId\"].isin(recommendations)]\n",
    "        for row in recommended_movies.itertuples():\n",
    "            print(row.title, \":\", row.genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a50c83ec-0a44-4952-b61d-5eb0722edc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies loaded\n",
      "Ratings loaded\n",
      "Embeddings loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 13:11:36.012450: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 13:11:36.027888: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 13:11:36.028055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 13:11:36.028656: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-12 13:11:36.029403: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 13:11:36.029517: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 13:11:36.029613: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 13:11:39.021277: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 13:11:39.021418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 13:11:39.021510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 13:11:39.021595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20346 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:08:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item tensor generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 13:11:39.512485: I scann/partitioning/partitioner_factory_base.cc:59] Size of sampled dataset for training partition: 62423\n",
      "2023-03-12 13:11:42.046129: I ./scann/partitioning/kmeans_tree_partitioner_utils.h:88] PartitionerFactory ran in 2.53359462s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scann initialized\n",
      "Model loaded\n",
      "Tokenizer loaded\n",
      "CF loaded\n"
     ]
    }
   ],
   "source": [
    "# Instantiate an instance of it, this will take a few moments as\n",
    "# in the initialization it loads into memory all of the requisite data\n",
    "personalisedRecommender = personalisedSearcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdabb92d-a2ec-4da6-85e8-0af2483fbb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step\n",
      "Showing recommendations for user: 4232\n",
      "====================================\n",
      "Movies with high ratings from user\n",
      "--------------------------------\n",
      "Dead Man Walking (1995) : Crime|Drama\n",
      "Usual Suspects, The (1995) : Crime|Mystery|Thriller\n",
      "Shawshank Redemption, The (1994) : Crime|Drama\n",
      "Fargo (1996) : Comedy|Crime|Drama|Thriller\n",
      "Insider, The (1999) : Drama|Thriller\n",
      "--------------------------------\n",
      "Top movie recommendations\n",
      "--------------------------------\n",
      "Tut (2015) : (no genres listed)\n",
      "Fant : (no genres listed)\n",
      "Thithi (2015) : (no genres listed)\n",
      "Tibetana : (no genres listed)\n",
      "Оно (1990) : (no genres listed)\n",
      "The OA : (no genres listed)\n",
      "Zero : (no genres listed)\n",
      "Since : (no genres listed)\n",
      "The Body : (no genres listed)\n",
      "Twice : (no genres listed)\n"
     ]
    }
   ],
   "source": [
    "personalisedRecommender.print_recs(4232, \"toto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62693e9-6d87-4bac-b4df-e45fe5c883ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elon-musk",
   "language": "python",
   "name": "elon-musk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
